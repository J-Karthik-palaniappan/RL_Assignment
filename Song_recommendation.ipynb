{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Define a simple Song class to hold song details\n",
        "class Song:\n",
        "    def __init__(self, song_id, description, genre, year):\n",
        "        self.song_id = song_id\n",
        "        self.description = description\n",
        "        self.genre = genre\n",
        "        self.year = year\n",
        "        self.similarity_score = 0\n",
        "\n",
        "# Define the K-armed bandit agent\n",
        "class KArmedBandit:\n",
        "    def __init__(self, songs, embedding_model=None, input_embedder=None):\n",
        "        self.songs = songs  # List of Song objects\n",
        "        self.num_songs = len(songs)\n",
        "        self.previous_songs = []  # Track previously suggested songs\n",
        "        self.embedding_model = embedding_model  # Pre-trained embedding model (Sentence-BERT)\n",
        "        self.input_embedder = input_embedder  # Model to embed the user input\n",
        "        self.song_rewards = np.zeros(self.num_songs)  # Rewards for each song\n",
        "\n",
        "    def encode_input(self, mood, style, year):\n",
        "        # One-hot encoding for simplicity (could be embeddings)\n",
        "        input_features = np.array([mood, style, year])\n",
        "        encoder = OneHotEncoder(sparse_output=False)\n",
        "        encoded_input = encoder.fit_transform(input_features.reshape(-1, 1))\n",
        "        return encoded_input.flatten()\n",
        "\n",
        "    def get_similarity(self, user_input, song):\n",
        "      # Embed user input into the same space as song descriptions\n",
        "      user_input_embedding = self.input_embedder(user_input)\n",
        "\n",
        "      # Ensure user_input_embedding does not require gradients\n",
        "      user_input_embedding = user_input_embedding.detach().numpy()  # Detach from computation graph and convert to numpy\n",
        "\n",
        "      # Get the song description embedding (already a numpy array)\n",
        "      song_vector = self.embedding_model.encode([song.description])[0]  # Get embedding of song description\n",
        "\n",
        "      # Calculate cosine similarity between user input embedding and song description embedding\n",
        "      similarity = cosine_similarity([user_input_embedding], [song_vector])[0][0]\n",
        "      return similarity\n",
        "\n",
        "\n",
        "    def recommend(self, user_input):\n",
        "        # Calculate similarity for all songs\n",
        "        for i, song in enumerate(self.songs):\n",
        "            song.similarity_score = self.get_similarity(user_input, song)\n",
        "\n",
        "        # Exploration vs Exploitation - Choose song based on similarity and past rewards\n",
        "        if np.random.rand() < 0.2:  # Exploration (20% of the time)\n",
        "            song_idx = np.random.choice(self.num_songs)\n",
        "        else:  # Exploitation - Recommend based on similarity to user input\n",
        "            song_idx = np.argmax(self.song_rewards)\n",
        "\n",
        "        # Penalize for previously recommended song\n",
        "        if self.songs[song_idx].song_id in self.previous_songs:\n",
        "            reward = -1  # Penalize for repeating songs\n",
        "        else:\n",
        "            reward = self.songs[song_idx].similarity_score\n",
        "            self.previous_songs.append(self.songs[song_idx].song_id)\n",
        "\n",
        "        # Update rewards based on similarity to user input and previous song similarity\n",
        "        self.song_rewards[song_idx] += reward\n",
        "\n",
        "        return self.songs[song_idx], reward\n",
        "\n",
        "\n",
        "# Simple embedding model for user input (1 layer NN)\n",
        "class InputEmbedder(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(InputEmbedder, self).__init__()\n",
        "        self.fc = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# Example dataset\n",
        "songs = [\n",
        "    Song(1, \"Upbeat jazz song with piano and saxophone.\", \"jazz\", \"old\"),\n",
        "    Song(2, \"Calm melody with piano and strings.\", \"melody\", \"mid\"),\n",
        "    Song(3, \"Instrumental rock with electric guitar.\", \"instrumental\", \"recent\"),\n",
        "    Song(4, \"Energetic pop song with strong beats.\", \"pop\", \"trending\"),\n",
        "    # Add more songs...\n",
        "]\n",
        "\n",
        "# Initialize the bandit agent with the list of songs and a pre-trained embedding model\n",
        "embedding_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')  # Load pre-trained Sentence-BERT model\n",
        "input_embedder = InputEmbedder(input_dim=9, output_dim=384)  # Simple NN model to embed user input into 384 dimensions\n",
        "bandit_agent = KArmedBandit(songs, embedding_model, input_embedder)\n",
        "\n",
        "# Example user input (one-hot encoded mood/style/year)\n",
        "user_input = bandit_agent.encode_input(mood=\"happy\", style=\"jazz\", year=\"old\")\n",
        "\n",
        "# Convert to torch tensor\n",
        "user_input_tensor = torch.tensor(user_input, dtype=torch.float32)\n",
        "\n",
        "# Get song recommendation\n",
        "recommended_song, reward = bandit_agent.recommend(user_input_tensor)\n",
        "\n",
        "print(f\"Recommended Song: {recommended_song.song_id}, Reward: {reward}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WrWEPe_fezm",
        "outputId": "4f2eaf38-c1df-42f0-fd90-da90ee09a0e0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended Song: 1, Reward: 0.055349960923194885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6mf9bp0mg4YI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}